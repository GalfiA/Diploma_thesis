{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:60% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:60% !important; }</style>\"))\n",
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%pylab inline\n",
    "import tensorflow as tf\n",
    "import re\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split as split\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_to_number = {\"O\": 0, \"B-LOC\": 1, \"I-LOC\": 2, \"B-MISC\": 3, \"I-MISC\": 4, \"B-PER\": 5, \"I-PER\": 6, \"B-ORG\": 7, \"I-ORG\": 8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_sentence(file_path):\n",
    "    file_path = Path(file_path)\n",
    "    \n",
    "    raw_text = file_path.read_text().strip()\n",
    "    raw_sentences = re.split(r'\\n\\t?\\n', raw_text)\n",
    "    \n",
    "    sentence_tokens = []\n",
    "    sentence_tags = []\n",
    "    \n",
    "    for sents in raw_sentences:\n",
    "        tokens = []\n",
    "        tags = []\n",
    "        \n",
    "        for line in sents.split('\\n'):\n",
    "            token = line.split()[0]\n",
    "            tag = line.split()[3]\n",
    "            \n",
    "            tokens.append(token)\n",
    "            # tags.append(entity_to_number[tag])\n",
    "            tags.append(tag)\n",
    "            \n",
    "        sentence_tokens.append(tokens)\n",
    "        sentence_tags.append(tags)\n",
    "    \n",
    "    return sentence_tokens, sentence_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_full, train_tags_full = read_and_sentence('E:\\Egyetem\\Diplomaterv\\data\\conllpp_train.txt')\n",
    "dev_data_full, dev_tags_full = read_and_sentence('E:\\Egyetem\\Diplomaterv\\data\\conllpp_dev.txt')\n",
    "test_data_full, test_tags_full = read_and_sentence('E:\\Egyetem\\Diplomaterv\\data\\conllpp_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data_full[:40000]\n",
    "train_tags = train_tags_full[:40000]\n",
    "\n",
    "dev_data = dev_data_full[:10000]\n",
    "dev_tags = dev_tags_full[:10000]\n",
    "\n",
    "test_data = test_data_full[:10000]\n",
    "test_tags = test_tags_full[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_words = [i for sublist in train_data for i in sublist]\n",
    "dv_words = [i for sublist in dev_data for i in sublist]\n",
    "tst_words = [i for sublist in test_data for i in sublist]\n",
    "\n",
    "tr_tags = [i for sublist in train_tags for i in sublist]\n",
    "dv_tags = [i for sublist in dev_tags for i in sublist]\n",
    "tst_tags = [i for sublist in test_tags for i in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vocab(word_list):\n",
    "    unique_list = []\n",
    "    vocab = {}\n",
    "    \n",
    "    for val in word_list:\n",
    "        if val not in unique_list:\n",
    "            unique_list.append(val)\n",
    "            \n",
    "    for i, l in enumerate(unique_list):\n",
    "        vocab[l] = i\n",
    "    return vocab\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vocab = create_vocab(tr_words)\n",
    "og_length = len(word_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_vocab = create_vocab(tr_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'O': 0,\n",
       " 'B-ORG': 1,\n",
       " 'B-MISC': 2,\n",
       " 'B-PER': 3,\n",
       " 'I-PER': 4,\n",
       " 'B-LOC': 5,\n",
       " 'I-ORG': 6,\n",
       " 'I-MISC': 7,\n",
       " 'I-LOC': 8}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(label_vocab))\n",
    "label_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23624"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vocab[\"UNK\"] = og_length\n",
    "word_vocab[\"PAD\"] = og_length+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23626"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(word_vocab)\n",
    "OUT_DIM = len(label_vocab)\n",
    "EMBED_DIM = 100\n",
    "HIDDEN_DIM = 20\n",
    "learning_rate = 0.001\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_datasets(sentences, labels):\n",
    "    \n",
    "    sentence_to_ix = []\n",
    "    label_to_ix = []\n",
    "    \n",
    "    for sent in sentences:\n",
    "        current_sent = []\n",
    "        \n",
    "        for word in sent:\n",
    "            if word in word_vocab.keys():\n",
    "                current_sent.append(word_vocab[word])\n",
    "            else:\n",
    "                current_sent.append(word_vocab[\"UNK\"])\n",
    "        \n",
    "        sentence_to_ix.append(current_sent)\n",
    "        \n",
    "    for label in labels:\n",
    "        l = [label_vocab[lab] for lab in label]\n",
    "        label_to_ix.append(l)\n",
    "   \n",
    "    return sentence_to_ix, label_to_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sent_ix, train_label_ix = prepare_datasets(train_data, train_tags)\n",
    "dev_sent_ix, dev_label_ix = prepare_datasets(dev_data, dev_tags)\n",
    "test_sent_ix, test_label_ix = prepare_datasets(test_data, test_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0],\n",
       " [1891, 676, 23624, 23624, 23624, 3395, 71, 21354, 2337, 23624, 10615, 9],\n",
       " [23624, 23624],\n",
       " [23624, 71, 868, 1139, 1140, 23624],\n",
       " [1807,\n",
       "  1396,\n",
       "  40,\n",
       "  3410,\n",
       "  162,\n",
       "  201,\n",
       "  6199,\n",
       "  1906,\n",
       "  2142,\n",
       "  22,\n",
       "  79,\n",
       "  7123,\n",
       "  1895,\n",
       "  2519,\n",
       "  788,\n",
       "  705,\n",
       "  236,\n",
       "  79,\n",
       "  8174,\n",
       "  8521,\n",
       "  2724,\n",
       "  1908,\n",
       "  18,\n",
       "  1162,\n",
       "  9]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sent_ix[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = max([len(s) for s in train_sent_ix])\n",
    "train_data_vecs = word_vocab[\"PAD\"] * np.ones((len(train_sent_ix), max_len))\n",
    "train_label_vecs = -1 * np.ones((len(train_sent_ix), max_len))\n",
    "\n",
    "for j in range(len(train_sent_ix)):\n",
    "    current_len = len(train_sent_ix[j])\n",
    "    train_data_vecs[j][:current_len] = train_sent_ix[j]\n",
    "    train_label_vecs[j][:current_len] = train_label_ix[j]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = max([len(s) for s in test_sent_ix])\n",
    "test_data_vecs = word_vocab[\"PAD\"] * np.ones((len(test_sent_ix), max_len))\n",
    "test_label_vecs = -1 * np.ones((len(test_sent_ix), max_len))\n",
    "\n",
    "for j in range(len(test_sent_ix)):\n",
    "    current_len = len(test_sent_ix[j])\n",
    "    test_data_vecs[j][:current_len] = test_sent_ix[j]\n",
    "    test_label_vecs[j][:current_len] = test_label_ix[j]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_vecs = torch.LongTensor(train_data_vecs)\n",
    "train_label_vecs = torch.LongTensor(train_label_vecs)\n",
    "\n",
    "test_data_vecs = torch.LongTensor(test_data_vecs)\n",
    "test_label_vecs = torch.LongTensor(test_label_vecs)\n",
    "\n",
    "# train_data_vecs = tf.Variable(train_data_vecs)\n",
    "# train_label_vecs = tf.Variable(train_label_vecs)\n",
    "# test_data_vecs = tf.Variable(test_data_vecs)\n",
    "# test_label_vecs = tf.Variable(test_label_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_data_loader = [(sample, label) for sample, label in zip(train_data_vecs, train_label_vecs)]\n",
    "val_data_loader = [(sample, label) for sample, label in zip(test_data_vecs, test_label_vecs)]\n",
    "\n",
    "train_iterator = DataLoader(tr_data_loader,\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            shuffle=True,\n",
    "                            )\n",
    "\n",
    "valid_iterator = DataLoader(val_data_loader,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=False,\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, num_labels):\n",
    "        super(RNN, self).__init__()\n",
    "    \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "    \n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "    \n",
    "        self.fc = nn.Linear(hidden_dim, num_labels)\n",
    "        \n",
    "    def forward(self, s):\n",
    "        \n",
    "        s = self.embedding(s)\n",
    "        s, _ = self.lstm(s)\n",
    "        s = s.view(-1, s.shape[2])\n",
    "        s = self.fc(s)\n",
    "        \n",
    "        return F.log_softmax(s, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, num_labels):\n",
    "        super(LSTM, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = HIDDEN_DIM\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "        \n",
    "        self.hidden2tag = nn.Linear(hidden_dim, num_labels)\n",
    "        \n",
    "    def forward(self, sentence):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        \n",
    "        lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n",
    "        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
    "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
    "        return tag_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "def class_performance(preds, y):\n",
    "\n",
    "    rounded_preds = preds.argmax(1)\n",
    "\n",
    "    precision, recall, fscore, support = precision_recall_fscore_support(\n",
    "        rounded_preds.cpu(), y.cpu()\n",
    "    )\n",
    "\n",
    "    return precision[1], recall[1], fscore[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(EMBED_DIM, HIDDEN_DIM, VOCAB_SIZE, OUT_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_prec = 0\n",
    "    epoch_recall = 0\n",
    "    epoch_fscore = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for texts, labels in iterator:\n",
    "        texts = texts.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "                  \n",
    "        predictions = model(texts)\n",
    "\n",
    "        loss = criterion(predictions, labels)\n",
    "        prec, recall, fscore = class_performance(predictions, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_prec += prec.item()\n",
    "        epoch_recall = recall.item()\n",
    "        epoch_fscore = fscore.item()\n",
    "        \n",
    "    return (epoch_loss / len(iterator),\n",
    "            epoch_prec / len(iterator),\n",
    "            epoch_recall / len(iterator),\n",
    "            epoch_fscore / len(iterator),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_prec = 0\n",
    "    epoch_recall = 0\n",
    "    epoch_fscore = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for texts, labels in iterator:\n",
    "            \n",
    "            texts = texts.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            predictions = model(texts)\n",
    "            loss = criterion(predictions, labels)\n",
    "            \n",
    "            prec, recall, fscore = class_performance(predictions, labels)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_prec += prec.item()\n",
    "            epoch_recall += recall.item()\n",
    "            epoch_fscore += fscore.item()\n",
    "        \n",
    "    return (\n",
    "        epoch_loss / len(iterator),\n",
    "        epoch_prec / len(iterator),\n",
    "        epoch_recall / len(iterator),\n",
    "        epoch_fscore / len(iterator),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-4052771e3fa9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_prec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_rec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_fscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mvalid_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_prec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_rec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_fscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_iterator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-29-c7d449405919>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, iterator, optimizer, criterion)\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Egyetem\\Anaconda_python\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-24-f16afdc993b0>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, s)\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead."
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "N_EPOCHS = 15\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_prec, train_rec, train_fscore = train(model, train_iterator, optimizer, criterion)\n",
    "    \n",
    "    valid_loss, valid_prec, valid_rec, valid_fscore = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    print(f\"Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s\")\n",
    "    print(f\"\\tTrain Loss: {train_loss:.3f} | Train Prec: {train_prec*100:.2f}% | Train Rec: {train_rec*100:.2f}% | Train Fscore: {train_fscore*100:.2f}%\")\n",
    "    print(f\"\\t Val. Loss: {valid_loss:.3f} |  Val Prec: {valid_prec*100:.2f}% | Val Rec: {valid_rec*100:.2f}% | Val Fscore: {valid_fscore*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
